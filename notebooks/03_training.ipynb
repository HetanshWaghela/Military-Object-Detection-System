{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Ce1aaAyVm3"
      },
      "source": [
        "# üöÄ Notebook 3: Training (Colab Ready)\n",
        "\n",
        "## Military Object Detection with YOLOv8\n",
        "\n",
        "**‚ö° OPTIMIZED**: Single model, 20 epochs, ~15-30 min on GPU\n",
        "\n",
        "### Steps:\n",
        "1. Upload `data.zip` to Colab (or mount Drive)\n",
        "2. Run all cells\n",
        "3. Download trained model at the end\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gFQipMoyVm3"
      },
      "source": [
        "## 1. Install & Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HVWfdlWcyVm4"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "!pip install -q ultralytics>=8.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9PNg-W3yVm4",
        "outputId": "0c6bc442-4914-4aac-dfe9-3928693eea58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.9.0+cu126\n",
            "‚úÖ GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import os, json, shutil, zipfile, warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check GPU\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    DEVICE = 0\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU! Go to Runtime > Change runtime type > GPU\")\n",
        "    DEVICE = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4WfsYV3yVm4"
      },
      "source": [
        "## 2. Upload Data\n",
        "\n",
        "**Option A**: Upload `data.zip` using the file browser (left sidebar)\n",
        "\n",
        "**Option B**: Mount Google Drive if `data.zip` is there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNtnHjwGyVm5",
        "outputId": "434fc5ba-acb4-4838-eca0-bb6278fdd78c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Running in Colab\n"
          ]
        }
      ],
      "source": [
        "# Detect environment\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    PROJECT_ROOT = Path('/content')\n",
        "    print(\"üöÄ Running in Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    PROJECT_ROOT = Path('..')\n",
        "    print(\"üíª Running locally\")\n",
        "\n",
        "# Create directories\n",
        "DATASET_ROOT = PROJECT_ROOT / 'military_object_dataset'\n",
        "CONFIG_DIR = PROJECT_ROOT / 'config'\n",
        "MODELS_DIR = PROJECT_ROOT / 'models'\n",
        "RUNS_DIR = PROJECT_ROOT / 'runs'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
        "\n",
        "for d in [MODELS_DIR, RUNS_DIR, RESULTS_DIR]:\n",
        "    d.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3sp1cMPyVm5",
        "outputId": "ad0b2720-5894-4582-c438-aa662dbdfd95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data already extracted!\n"
          ]
        }
      ],
      "source": [
        "# === UPLOAD/EXTRACT DATA ===\n",
        "\n",
        "DATA_ZIP = PROJECT_ROOT / 'data.zip'\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Check if data already extracted\n",
        "    if DATASET_ROOT.exists() and (CONFIG_DIR / 'dataset.yaml').exists():\n",
        "        print(\"‚úÖ Data already extracted!\")\n",
        "\n",
        "    # Check for data.zip in current directory\n",
        "    elif DATA_ZIP.exists():\n",
        "        print(\"üì¶ Found data.zip, extracting...\")\n",
        "        with zipfile.ZipFile(DATA_ZIP, 'r') as z:\n",
        "            z.extractall(PROJECT_ROOT)\n",
        "        print(\"‚úÖ Extracted!\")\n",
        "\n",
        "    # Try Google Drive\n",
        "    else:\n",
        "        print(\"üìÇ Mounting Google Drive...\")\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        # Check common locations\n",
        "        drive_paths = [\n",
        "            Path('/content/drive/MyDrive/data.zip'),\n",
        "            Path('/content/drive/MyDrive/hackathon/data.zip'),\n",
        "        ]\n",
        "\n",
        "        found = False\n",
        "        for drive_zip in drive_paths:\n",
        "            if drive_zip.exists():\n",
        "                print(f\"üì¶ Found {drive_zip}, copying...\")\n",
        "                shutil.copy(drive_zip, DATA_ZIP)\n",
        "                with zipfile.ZipFile(DATA_ZIP, 'r') as z:\n",
        "                    z.extractall(PROJECT_ROOT)\n",
        "                print(\"‚úÖ Extracted!\")\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        if not found:\n",
        "            print(\"‚ùå data.zip not found!\")\n",
        "            print(\"   Please upload data.zip to /content or to Google Drive root\")\n",
        "else:\n",
        "    print(\"üíª Local mode - using existing data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGIpR9G_yVm5",
        "outputId": "726b7e86-4546-47cc-b458-ba1a6e5cc07e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset YAML: /content/config/dataset.yaml\n",
            "‚úÖ Dataset root: /content/military_object_dataset\n",
            "   Train: 10000 | Val: 2941 | Test: 1396\n"
          ]
        }
      ],
      "source": [
        "# Verify data\n",
        "DATASET_YAML = CONFIG_DIR / 'dataset.yaml'\n",
        "\n",
        "if not DATASET_YAML.exists():\n",
        "    raise FileNotFoundError(f\"‚ùå Missing {DATASET_YAML}! Please upload data.zip\")\n",
        "\n",
        "print(f\"‚úÖ Dataset YAML: {DATASET_YAML}\")\n",
        "print(f\"‚úÖ Dataset root: {DATASET_ROOT}\")\n",
        "\n",
        "# Count images\n",
        "train_imgs = len(list((DATASET_ROOT / 'train' / 'images').glob('*')))\n",
        "val_imgs = len(list((DATASET_ROOT / 'val' / 'images').glob('*')))\n",
        "test_imgs = len(list((DATASET_ROOT / 'test' / 'images').glob('*')))\n",
        "print(f\"   Train: {train_imgs} | Val: {val_imgs} | Test: {test_imgs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utsRnoaByVm5"
      },
      "source": [
        "## 3. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4HQwqK56yVm6"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7e9quL4yVm6",
        "outputId": "13e34d4e-84cf-4533-c684-e050a68b3afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Training Config:\n",
            "   model: yolov8s.pt\n",
            "   epochs: 11\n",
            "   batch: 16\n",
            "   imgsz: 640\n",
            "   patience: 5\n",
            "   optimizer: AdamW\n",
            "   lr0: 0.002\n"
          ]
        }
      ],
      "source": [
        "# Training config\n",
        "CONFIG = {\n",
        "    'model': 'yolov8s.pt',  # Balanced speed/accuracy\n",
        "    'epochs': 11,           # Enough for good results\n",
        "    'batch': 16,\n",
        "    'imgsz': 640,\n",
        "    'patience': 5,          # Early stopping\n",
        "    'optimizer': 'AdamW',\n",
        "    'lr0': 0.002,\n",
        "}\n",
        "\n",
        "print(\"‚ö° Training Config:\")\n",
        "for k, v in CONFIG.items():\n",
        "    print(f\"   {k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TfaRAS_yVm6",
        "outputId": "3d82ae10-a71d-4aed-d827-99d4aca43829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üöÄ STARTING TRAINING\n",
            "============================================================\n",
            "Ultralytics 8.3.237 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/config/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=11, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.002, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=military_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/military_detector, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2120692  ultralytics.nn.modules.head.Detect           [12, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,140,244 parameters, 11,140,228 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1289.4¬±330.0 MB/s, size: 92.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/military_object_dataset/train/labels.cache... 10000 images, 123 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 14.6Mit/s 0.0s\n",
            "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 10, len(boxes) = 19956. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 512.1¬±536.9 MB/s, size: 175.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/military_object_dataset/val/labels.cache... 2941 images, 273 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2941/2941 1.4Mit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/military_detector/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/military_detector\u001b[0m\n",
            "Starting training for 11 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/11      5.76G       1.54      2.222      1.597         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.6it/s 3:60\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.6it/s 34.7s\n",
            "                   all       2941       5081      0.267      0.152      0.134     0.0659\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/11      5.79G      1.747      2.293      1.854         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.7it/s 34.4s\n",
            "                   all       2941       5081      0.408      0.152      0.112     0.0587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/11      5.83G      1.667      2.097      1.769         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:34\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.7it/s 33.6s\n",
            "                   all       2941       5081      0.384      0.182      0.168     0.0874\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/11      5.83G      1.572      1.897      1.687         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.6it/s 35.2s\n",
            "                   all       2941       5081       0.23      0.265      0.207      0.112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/11      5.83G      1.476      1.708      1.616         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.8it/s 33.4s\n",
            "                   all       2941       5081      0.501      0.296      0.261      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/11      5.83G      1.412      1.574      1.563         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.6it/s 35.1s\n",
            "                   all       2941       5081      0.398      0.342      0.291      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/11      5.83G       1.36      1.462      1.515         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.7it/s 34.1s\n",
            "                   all       2941       5081       0.58      0.282      0.295      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/11      5.83G      1.305      1.366      1.474         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.5it/s 37.5s\n",
            "                   all       2941       5081      0.553      0.331      0.359      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/11      5.83G      1.245      1.247      1.425         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.8it/s 33.3s\n",
            "                   all       2941       5081       0.48      0.389      0.368      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/11      5.83G      1.201      1.165      1.395         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.7it/s 34.4s\n",
            "                   all       2941       5081      0.532      0.397      0.389      0.239\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/11      5.83G      1.154      1.077      1.359         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 2.9it/s 3:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.7it/s 33.9s\n",
            "                   all       2941       5081      0.597      0.406       0.42      0.262\n",
            "\n",
            "11 epochs completed in 0.777 hours.\n",
            "Optimizer stripped from /content/runs/detect/military_detector/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from /content/runs/detect/military_detector/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating /content/runs/detect/military_detector/weights/best.pt...\n",
            "Ultralytics 8.3.237 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,130,228 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 92/92 2.3it/s 40.1s\n",
            "                   all       2941       5081      0.596      0.406      0.421      0.262\n",
            "    camouflage_soldier        385        510      0.684      0.625      0.667      0.332\n",
            "                weapon        222        358      0.571      0.454       0.47      0.318\n",
            "         military_tank        938       1787       0.74      0.833       0.81      0.518\n",
            "        military_truck         84        148      0.439      0.493      0.397       0.25\n",
            "      military_vehicle        149        307      0.453      0.446      0.392      0.282\n",
            "              civilian          1          1          1          0          0          0\n",
            "               soldier        420        745      0.778      0.526      0.616      0.328\n",
            "      civilian_vehicle         18         42      0.364      0.333      0.252      0.135\n",
            "    military_artillery         85        117      0.721     0.0171      0.209       0.12\n",
            "                trench          1          3          0          0          0          0\n",
            "     military_aircraft        594       1063      0.812      0.736      0.815      0.595\n",
            "Speed: 0.2ms preprocess, 3.4ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/military_detector\u001b[0m\n",
            "\n",
            "‚úÖ Training complete in 47.5 minutes\n"
          ]
        }
      ],
      "source": [
        "# === TRAIN ===\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ STARTING TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = YOLO(CONFIG['model'])\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "results = model.train(\n",
        "    data=str(DATASET_YAML.absolute()),\n",
        "    device=DEVICE,\n",
        "    epochs=CONFIG['epochs'],\n",
        "    batch=CONFIG['batch'],\n",
        "    imgsz=CONFIG['imgsz'],\n",
        "    patience=CONFIG['patience'],\n",
        "    optimizer=CONFIG['optimizer'],\n",
        "    lr0=CONFIG['lr0'],\n",
        "    project=str(RUNS_DIR / 'detect'),\n",
        "    name='military_detector',\n",
        "    exist_ok=True,\n",
        "    pretrained=True,\n",
        "    seed=SEED,\n",
        "    amp=True,\n",
        "    plots=True,\n",
        "    val=True,\n",
        "    workers=2,\n",
        ")\n",
        "\n",
        "training_time = (datetime.now() - start_time).total_seconds() / 60\n",
        "print(f\"\\n‚úÖ Training complete in {training_time:.1f} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efc_E1V0yVm6"
      },
      "source": [
        "## 4. Validate & Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjyaA_pXyVm6",
        "outputId": "86993332-1259-4df2-970e-012b2eaa42b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Training outputs: /content/runs/detect/military_detector\n",
            "üìÅ Best model: /content/runs/detect/military_detector/weights/best.pt\n"
          ]
        }
      ],
      "source": [
        "# Get best model path\n",
        "save_dir = Path(results.save_dir)\n",
        "best_model_path = save_dir / 'weights' / 'best.pt'\n",
        "\n",
        "print(f\"üìÅ Training outputs: {save_dir}\")\n",
        "print(f\"üìÅ Best model: {best_model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72pEZCAXyVm6",
        "outputId": "a6b98a1a-b486-4153-8e42-0b7cc5af13b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Running validation...\n",
            "Ultralytics 8.3.237 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,130,228 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1486.3¬±1105.5 MB/s, size: 96.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/military_object_dataset/val/labels.cache... 2941 images, 273 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2941/2941 5.9Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 184/184 3.7it/s 49.1s\n",
            "                   all       2941       5081      0.595      0.406      0.421      0.262\n",
            "    camouflage_soldier        385        510      0.681      0.627      0.664      0.332\n",
            "                weapon        222        358      0.579      0.453      0.472      0.318\n",
            "         military_tank        938       1787      0.739      0.831       0.81      0.518\n",
            "        military_truck         84        148      0.434      0.493      0.399      0.251\n",
            "      military_vehicle        149        307      0.454      0.447      0.392      0.284\n",
            "              civilian          1          1          1          0          0          0\n",
            "               soldier        420        745      0.775      0.526      0.615      0.328\n",
            "      civilian_vehicle         18         42       0.36      0.333      0.253      0.135\n",
            "    military_artillery         85        117      0.715     0.0171       0.21      0.117\n",
            "                trench          1          3          0          0          0          0\n",
            "     military_aircraft        594       1063      0.811      0.736      0.816      0.595\n",
            "Speed: 1.0ms preprocess, 7.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "\n",
            "============================================================\n",
            "üìä FINAL RESULTS\n",
            "============================================================\n",
            "   mAP@0.5:      0.4210\n",
            "   mAP@0.5:0.95: 0.2617\n",
            "   Precision:    0.5953\n",
            "   Recall:       0.4058\n",
            "   Training:     47.5 min\n"
          ]
        }
      ],
      "source": [
        "# Validate\n",
        "print(\"\\nüîç Running validation...\")\n",
        "best_model = YOLO(str(best_model_path))\n",
        "val_results = best_model.val(\n",
        "    data=str(DATASET_YAML.absolute()),\n",
        "    batch=16,\n",
        "    imgsz=640,\n",
        "    plots=True,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä FINAL RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"   mAP@0.5:      {val_results.box.map50:.4f}\")\n",
        "print(f\"   mAP@0.5:0.95: {val_results.box.map:.4f}\")\n",
        "print(f\"   Precision:    {val_results.box.mp:.4f}\")\n",
        "print(f\"   Recall:       {val_results.box.mr:.4f}\")\n",
        "print(f\"   Training:     {training_time:.1f} min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26_G13K9yVm6",
        "outputId": "68fdfbfd-7d68-4d98-f8cf-5d25cda30310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Model copied to: /content/models/best_model.pt\n",
            "üíæ Results saved to: /content/results/training_results.json\n"
          ]
        }
      ],
      "source": [
        "# Copy best model to models directory\n",
        "model_dst = MODELS_DIR / 'best_model.pt'\n",
        "shutil.copy(best_model_path, model_dst)\n",
        "print(f\"\\nüíæ Model copied to: {model_dst}\")\n",
        "\n",
        "# Save training results\n",
        "results_data = {\n",
        "    'model': CONFIG['model'],\n",
        "    'epochs': CONFIG['epochs'],\n",
        "    'mAP50': float(val_results.box.map50),\n",
        "    'mAP50-95': float(val_results.box.map),\n",
        "    'precision': float(val_results.box.mp),\n",
        "    'recall': float(val_results.box.mr),\n",
        "    'training_time_min': round(training_time, 1)\n",
        "}\n",
        "\n",
        "with open(RESULTS_DIR / 'training_results.json', 'w') as f:\n",
        "    json.dump(results_data, f, indent=2)\n",
        "\n",
        "print(f\"üíæ Results saved to: {RESULTS_DIR / 'training_results.json'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ram9VnGdyVm6"
      },
      "source": [
        "## 5. Download Model (Colab)\n",
        "\n",
        "**IMPORTANT**: Download the trained model before the Colab session ends!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "RUIgcwzXyVm6",
        "outputId": "1240a7fe-fdf9-4c24-d2d8-5dfd0567a5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading best_model.pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23b9304a-cd43-473f-ac29-9c4a7c2f80b1\", \"best_model.pt\", 22503082)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì• Downloading training_results.json...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_32a8c612-06b2-4574-8762-a0f5ae2c93b6\", \"training_results.json\", 204)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"üì• Downloading best_model.pt...\")\n",
        "    files.download(str(model_dst))\n",
        "\n",
        "    print(\"\\nüì• Downloading training_results.json...\")\n",
        "    files.download(str(RESULTS_DIR / 'training_results.json'))\n",
        "else:\n",
        "    print(f\"üíª Local mode - model saved at: {model_dst}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTr3OymJyVm6",
        "outputId": "f1fee3a7-1a48-4854-aa5d-366aa3eb7df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "‚úÖ TRAINING COMPLETE!\n",
            "============================================================\n",
            "\n",
            "üìã Next Steps:\n",
            "   1. Download best_model.pt (above)\n",
            "   2. Run Notebook 05 to generate predictions.zip\n",
            "   3. Submit predictions.zip to hackathon\n",
            "\n",
            "üí° TIP: Keep this Colab tab open and run Notebook 05 here!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ TRAINING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüìã Next Steps:\")\n",
        "print(\"   1. Download best_model.pt (above)\")\n",
        "print(\"   2. Run Notebook 05 to generate predictions.zip\")\n",
        "print(\"   3. Submit predictions.zip to hackathon\")\n",
        "print(\"\\nüí° TIP: Keep this Colab tab open and run Notebook 05 here!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}