{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ Notebook 5: Inference & Submission\n",
                "\n",
                "## HACKATHON SUBMISSION GENERATOR\n",
                "\n",
                "This notebook generates **YOLO-format prediction files** for all test images and creates a **ZIP file for submission**.\n",
                "\n",
                "**Output Format (per line):**\n",
                "```\n",
                "class_id x_center y_center width height confidence\n",
                "```\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q ultralytics opencv-python Pillow matplotlib tqdm PyYAML"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, json, zipfile, shutil\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import yaml\n",
                "import torch\n",
                "from ultralytics import YOLO\n",
                "from tqdm.notebook import tqdm\n",
                "from PIL import Image\n",
                "\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Paths\n",
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "    PROJECT_ROOT = Path('/content')\n",
                "except ImportError:\n",
                "    IN_COLAB = False\n",
                "    PROJECT_ROOT = Path('..')\n",
                "\n",
                "DATASET_ROOT = PROJECT_ROOT / 'military_object_dataset'\n",
                "CONFIG_DIR = PROJECT_ROOT / 'config'\n",
                "MODELS_DIR = PROJECT_ROOT / 'models'\n",
                "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
                "RESULTS_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "TEST_IMAGES = DATASET_ROOT / 'test' / 'images'\n",
                "\n",
                "# Create output directories for submission\n",
                "PREDICTIONS_DIR = RESULTS_DIR / 'yolo_predictions'\n",
                "PREDICTIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Load class config\n",
                "with open(CONFIG_DIR / 'dataset.yaml', 'r') as f:\n",
                "    dataset_config = yaml.safe_load(f)\n",
                "\n",
                "CLASS_NAMES = dataset_config['names']\n",
                "NUM_CLASSES = dataset_config['nc']\n",
                "\n",
                "print(f\"Classes: {NUM_CLASSES}\")\n",
                "print(f\"Test images dir: {TEST_IMAGES}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find best model\n",
                "best_model_path = MODELS_DIR / 'best_model.pt'\n",
                "\n",
                "if not best_model_path.exists():\n",
                "    runs_dir = PROJECT_ROOT / 'runs' / 'detect'\n",
                "    if runs_dir.exists():\n",
                "        for exp_dir in sorted(runs_dir.iterdir(), reverse=True):\n",
                "            candidate = exp_dir / 'weights' / 'best.pt'\n",
                "            if candidate.exists():\n",
                "                best_model_path = candidate\n",
                "                break\n",
                "\n",
                "if best_model_path.exists():\n",
                "    model = YOLO(str(best_model_path))\n",
                "    print(f\"‚úÖ Loaded: {best_model_path}\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No trained model! Run notebook 03 first.\")\n",
                "    model = YOLO('yolov8s.pt')  # Fallback"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Generate YOLO-Format Predictions\n",
                "\n",
                "**Format per line:** `class_id x_center y_center width height confidence`\n",
                "\n",
                "All values normalized to [0, 1] relative to image dimensions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_yolo_predictions(model, test_images_dir: Path, output_dir: Path, conf_threshold: float = 0.25):\n",
                "    \"\"\"\n",
                "    Generate YOLO-format .txt files for all test images.\n",
                "    \n",
                "    Format: class_id x_center y_center width height confidence\n",
                "    All coordinates normalized to [0,1].\n",
                "    \"\"\"\n",
                "    # Get all test images\n",
                "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
                "    test_images = []\n",
                "    for ext in image_extensions:\n",
                "        test_images.extend(list(test_images_dir.glob(ext)))\n",
                "    \n",
                "    print(f\"üì∏ Found {len(test_images)} test images\")\n",
                "    \n",
                "    # Clear output directory\n",
                "    for f in output_dir.glob('*.txt'):\n",
                "        f.unlink()\n",
                "    \n",
                "    # Device\n",
                "    device = 0 if torch.cuda.is_available() else 'cpu'\n",
                "    \n",
                "    total_detections = 0\n",
                "    empty_count = 0\n",
                "    \n",
                "    for img_path in tqdm(test_images, desc=\"Generating predictions\"):\n",
                "        # Get image dimensions\n",
                "        with Image.open(img_path) as img:\n",
                "            img_width, img_height = img.size\n",
                "        \n",
                "        # Run inference\n",
                "        results = model.predict(\n",
                "            str(img_path),\n",
                "            conf=conf_threshold,\n",
                "            iou=0.45,\n",
                "            imgsz=640,\n",
                "            device=device,\n",
                "            verbose=False\n",
                "        )\n",
                "        \n",
                "        result = results[0]\n",
                "        \n",
                "        # Output file: same name as image but .txt extension\n",
                "        txt_filename = img_path.stem + '.txt'\n",
                "        txt_path = output_dir / txt_filename\n",
                "        \n",
                "        # Write predictions\n",
                "        with open(txt_path, 'w') as f:\n",
                "            if len(result.boxes) > 0:\n",
                "                boxes = result.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]\n",
                "                classes = result.boxes.cls.cpu().numpy().astype(int)\n",
                "                confs = result.boxes.conf.cpu().numpy()\n",
                "                \n",
                "                for box, cls_id, conf in zip(boxes, classes, confs):\n",
                "                    x1, y1, x2, y2 = box\n",
                "                    \n",
                "                    # Convert to YOLO format (normalized x_center, y_center, width, height)\n",
                "                    x_center = ((x1 + x2) / 2) / img_width\n",
                "                    y_center = ((y1 + y2) / 2) / img_height\n",
                "                    width = (x2 - x1) / img_width\n",
                "                    height = (y2 - y1) / img_height\n",
                "                    \n",
                "                    # Write: class_id x_center y_center width height confidence\n",
                "                    f.write(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f} {conf:.6f}\\n\")\n",
                "                    total_detections += 1\n",
                "            else:\n",
                "                empty_count += 1\n",
                "                # Empty file for images with no detections\n",
                "                pass\n",
                "    \n",
                "    print(f\"\\n‚úÖ Generated {len(test_images)} prediction files\")\n",
                "    print(f\"   Total detections: {total_detections}\")\n",
                "    print(f\"   Empty predictions: {empty_count}\")\n",
                "    print(f\"   Output: {output_dir}\")\n",
                "    \n",
                "    return len(test_images)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions for ALL test images\n",
                "print(\"üöÄ Generating YOLO-format predictions...\\n\")\n",
                "\n",
                "num_predictions = generate_yolo_predictions(\n",
                "    model=model,\n",
                "    test_images_dir=TEST_IMAGES,\n",
                "    output_dir=PREDICTIONS_DIR,\n",
                "    conf_threshold=0.25\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create Submission ZIP"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_submission_zip(predictions_dir: Path, output_path: Path):\n",
                "    \"\"\"\n",
                "    Create a ZIP file containing all prediction .txt files.\n",
                "    \"\"\"\n",
                "    txt_files = list(predictions_dir.glob('*.txt'))\n",
                "    \n",
                "    print(f\"üì¶ Creating submission ZIP with {len(txt_files)} files...\")\n",
                "    \n",
                "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
                "        for txt_file in txt_files:\n",
                "            # Add file with just the filename (no directory structure)\n",
                "            zf.write(txt_file, txt_file.name)\n",
                "    \n",
                "    zip_size = output_path.stat().st_size / (1024 * 1024)  # MB\n",
                "    print(f\"\\n‚úÖ Submission ZIP created!\")\n",
                "    print(f\"   Path: {output_path}\")\n",
                "    print(f\"   Size: {zip_size:.2f} MB\")\n",
                "    print(f\"   Files: {len(txt_files)}\")\n",
                "    \n",
                "    return output_path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create submission ZIP\n",
                "SUBMISSION_ZIP = RESULTS_DIR / 'predictions.zip'\n",
                "\n",
                "create_submission_zip(\n",
                "    predictions_dir=PREDICTIONS_DIR,\n",
                "    output_path=SUBMISSION_ZIP\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Verify Submission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify: Check a sample prediction file\n",
                "sample_txts = list(PREDICTIONS_DIR.glob('*.txt'))[:3]\n",
                "\n",
                "print(\"üìã Sample prediction files:\")\n",
                "print(\"=\"*60)\n",
                "for txt_path in sample_txts:\n",
                "    print(f\"\\n{txt_path.name}:\")\n",
                "    with open(txt_path, 'r') as f:\n",
                "        content = f.read()\n",
                "        if content.strip():\n",
                "            lines = content.strip().split('\\n')[:5]\n",
                "            for line in lines:\n",
                "                print(f\"  {line}\")\n",
                "            if len(content.strip().split('\\n')) > 5:\n",
                "                print(f\"  ... ({len(content.strip().split(chr(10)))} total detections)\")\n",
                "        else:\n",
                "            print(\"  (no detections)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify ZIP contents\n",
                "print(\"\\nüì¶ ZIP Contents (first 10 files):\")\n",
                "print(\"=\"*60)\n",
                "with zipfile.ZipFile(SUBMISSION_ZIP, 'r') as zf:\n",
                "    files = zf.namelist()\n",
                "    for f in files[:10]:\n",
                "        print(f\"  {f}\")\n",
                "    if len(files) > 10:\n",
                "        print(f\"  ... ({len(files)} total files)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify all test images have corresponding .txt files\n",
                "test_image_names = set(p.stem for p in TEST_IMAGES.glob('*.jpg'))\n",
                "test_image_names.update(p.stem for p in TEST_IMAGES.glob('*.png'))\n",
                "test_image_names.update(p.stem for p in TEST_IMAGES.glob('*.jpeg'))\n",
                "\n",
                "prediction_names = set(p.stem for p in PREDICTIONS_DIR.glob('*.txt'))\n",
                "\n",
                "missing = test_image_names - prediction_names\n",
                "\n",
                "if missing:\n",
                "    print(f\"‚ö†Ô∏è WARNING: Missing predictions for {len(missing)} images!\")\n",
                "    for name in list(missing)[:5]:\n",
                "        print(f\"   - {name}\")\n",
                "else:\n",
                "    print(f\"‚úÖ All {len(test_image_names)} test images have predictions!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*70)\n",
                "print(\"üéØ SUBMISSION READY\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nüì¶ SUBMISSION FILES:\")\n",
                "print(f\"   ZIP: {SUBMISSION_ZIP}\")\n",
                "print(f\"   Predictions: {PREDICTIONS_DIR}\")\n",
                "print(f\"\\nüìã STATISTICS:\")\n",
                "print(f\"   Test images: {len(test_image_names)}\")\n",
                "print(f\"   Prediction files: {len(prediction_names)}\")\n",
                "print(f\"\\n‚úÖ Download 'predictions.zip' and submit!\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For Colab: Download the ZIP\n",
                "if IN_COLAB:\n",
                "    from google.colab import files\n",
                "    print(\"üì• Downloading submission ZIP...\")\n",
                "    files.download(str(SUBMISSION_ZIP))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}